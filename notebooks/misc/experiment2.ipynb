{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "539d69df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from db import execute_query\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "519b0410",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create the calibration/test splits\"\"\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "query = f\"\"\"\n",
    "select audio_id, background_modifier_id, audio_info_id\n",
    "from audio_data \n",
    "\"\"\"\n",
    "\n",
    "class Audio:\n",
    "    def __init__(self, row):\n",
    "        self.audio_id = row[0]\n",
    "        self.background_modifier = row[1]\n",
    "        self.info_id = row[2]\n",
    "\n",
    "data = execute_query(query)\n",
    "audio_ids = np.array([Audio(d) for d in data])\n",
    "background_modifier_ids = np.array([d[1] for d in data])\n",
    "audio_info_ids = np.array([d[2] for d in data])\n",
    "\n",
    "labels = np.array(list(zip(background_modifier_ids, audio_info_ids)))\n",
    "audio_train, audio_test, _, _ = train_test_split(audio_ids, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "calibration_ids = [audio.audio_id for audio in audio_train]\n",
    "calibration_features = [audio.background_modifier for audio in audio_train]\n",
    "\n",
    "lst = [audio for audio in audio_test if audio.background_modifier == 2]\n",
    "validation_ids = [audio.audio_id for audio in lst]\n",
    "validation_features = [audio.background_modifier for audio in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12b5abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(lst):\n",
    "    m = defaultdict(int)\n",
    "    for i in lst:\n",
    "        m[i.background_modifier] += 1\n",
    "        \n",
    "    return m\n",
    "\n",
    "def count1(lst):\n",
    "    m = defaultdict(int)\n",
    "    for i in lst:\n",
    "        m[i.info_id] += 1\n",
    "        \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0308df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample dictionary data\n",
    "data = count(audio_train)\n",
    "\n",
    "# Extract keys and values from the dictionary\n",
    "keys = [\"No background noise\", \"Cafe\", \"Highway\", \"Park\"]\n",
    "values = [data[k] for k in sorted(data.keys())]\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.bar(keys, values, color='lightblue')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Background noise')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Background noise distribution')\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea33823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample dictionary data\n",
    "data = count(lst)\n",
    "\n",
    "# Extract keys and values from the dictionary\n",
    "keys = [\"No background noise\", \"Cafe\", \"Highway\", \"Park\"]\n",
    "values = [0, 0, 445, 0]\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.bar(keys, values, color='lightblue')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Background noise')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Background noise distribution')\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8162bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample dictionary data\n",
    "data = count1(lst)\n",
    "\n",
    "# Extract keys and values from the dictionary\n",
    "keys = list(data.keys())\n",
    "values = list(data.values())\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.bar(keys, values, color='lightblue')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Voice Command ID')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Voice Command Distribution')\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b6245d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Construct the datasets for Conformal Risk Control\"\"\"\n",
    "\n",
    "def create_mapping(data):\n",
    "    mapping = {}\n",
    "    idx = 0\n",
    "    for item in data:\n",
    "        audio_id = item[0]\n",
    "        if audio_id not in mapping:\n",
    "            mapping[audio_id] = idx\n",
    "            idx += 1\n",
    "    return mapping\n",
    "\n",
    "n = len(calibration_ids)\n",
    "calibration_predictions = [[] for _ in range(n)]\n",
    "calibration_confidence_scores = [[] for _ in range(n)]\n",
    "calibration_word_error_rates = [[] for _ in range(n)]\n",
    "calibration_audio_info_ids = [[] for _ in range(n)]\n",
    "c_background_modifier_ids = [[] for _ in range(n)]\n",
    "\n",
    "query = f\"\"\"\n",
    "select Audio_ID, Prediction, Confidence_Score, Word_Error_Rate, Audio_Info_ID, Background_Modifier_ID\n",
    "from audio_data \n",
    "natural join audio_predictions\n",
    "where audio_id in {tuple(calibration_ids)}\n",
    "\"\"\"\n",
    "rows = execute_query(query)\n",
    "mapping = create_mapping(rows)\n",
    "\n",
    "for row in rows:\n",
    "    idx = mapping[row[0]]\n",
    "    calibration_predictions[idx].append(row[1])\n",
    "    calibration_confidence_scores[idx].append(row[2])\n",
    "    calibration_word_error_rates[idx].append(row[3])\n",
    "    calibration_audio_info_ids[idx].append(row[4])\n",
    "    c_background_modifier_ids[idx].append(row[5])\n",
    "        \n",
    "n = len(validation_ids)\n",
    "validation_predictions = [[] for _ in range(n)]\n",
    "validation_confidence_scores = [[] for _ in range(n)]\n",
    "validation_word_error_rates = [[] for _ in range(n)]\n",
    "validation_audio_info_ids = [[] for _ in range(n)]\n",
    "v_background_modifier_ids = [[] for _ in range(n)]\n",
    "\n",
    "query = f\"\"\"\n",
    "select Audio_ID, Prediction, Confidence_Score, Word_Error_Rate, Audio_Info_ID, Background_Modifier_ID\n",
    "from audio_data \n",
    "natural join audio_predictions\n",
    "where audio_id in {tuple(validation_ids)}\n",
    "\"\"\"\n",
    "rows = execute_query(query)\n",
    "mapping = create_mapping(rows)\n",
    "\n",
    "for row in rows:\n",
    "    idx = mapping[row[0]]\n",
    "    validation_predictions[idx].append(row[1])\n",
    "    validation_confidence_scores[idx].append(row[2])\n",
    "    validation_word_error_rates[idx].append(row[3])\n",
    "    validation_audio_info_ids[idx].append(row[4])\n",
    "    v_background_modifier_ids[idx].append(row[5])\n",
    "    \n",
    "def flat(input_list):\n",
    "    flattened_list = []\n",
    "    for sublist in input_list:\n",
    "        if isinstance(sublist, list):\n",
    "            if sublist:  # Check if the sublist is not empty\n",
    "                flattened_list.append(sublist[0])\n",
    "        else:\n",
    "            flattened_list.append(sublist)\n",
    "    return flattened_list\n",
    "    \n",
    "calibration_features = flat(c_background_modifier_ids)\n",
    "validation_features = flat(v_background_modifier_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aaa5d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code to compute the weight for each calibration data point\"\"\"\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def compute_weight_schedule(calibration_features, validation_features):\n",
    "    X, y = calibration_features + validation_features, [0] * len(calibration_features) + [1] * len(validation_features)\n",
    "    X, y = np.array(X).reshape(-1, 1), np.array(y)\n",
    "\n",
    "    binary_classifier = RandomForestClassifier()\n",
    "    binary_classifier.fit(X, y)\n",
    "    \n",
    "    weight_fn = {}\n",
    "    feature_set = set(calibration_features) | set(validation_features)\n",
    "    for feature in feature_set:\n",
    "        probabilities = binary_classifier.predict_proba([[feature]])[0]\n",
    "        print(feature, probabilities)\n",
    "        weight_fn[feature] = probabilities[1] / (1 - probabilities[1])\n",
    "\n",
    "    weight_schedule = [weight_fn[feature] for feature in calibration_features]\n",
    "    return weight_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cad63e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Uncomment this block to use weighted CRC for calibration\"\"\"\n",
    "\n",
    "weights = compute_weight_schedule(calibration_features, validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a73fb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Uncomment this block to use unweighted CRC for calibration\"\"\"\n",
    "\n",
    "# weights = np.array([1] * len(calibration_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64363c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Conformal prediction parameters\"\"\"\n",
    "\n",
    "B = 1\n",
    "alpha = 0.75\n",
    "threshold = 0.4  # target word error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "23f01dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code for Conformal Risk Control\"\"\"\n",
    "\n",
    "import functools\n",
    "import numpy as np\n",
    "from scipy.optimize import brentq\n",
    "\n",
    "def c_lam(lam, smx):\n",
    "    \"\"\"Compute prediction set indexes using lambda\"\"\"\n",
    "    prefix_sums = np.cumsum(smx, axis=1)\n",
    "    threshold_indexes = np.zeros(prefix_sums.shape[0], dtype=int)\n",
    "    for idx, row in enumerate(prefix_sums):\n",
    "        threshold_idx = np.argmax(row >= lam)\n",
    "        threshold_indexes[idx] = threshold_idx if row[threshold_idx] >= lam else row.shape[0] - 1\n",
    "    return threshold_indexes\n",
    "\n",
    "def loss(wers, wer_target):\n",
    "    \"\"\"Compute array of losses\"\"\"\n",
    "    return np.array([int(np.all(w >= wer_target)) for w in wers])\n",
    "\n",
    "def losses(lam, smx, wers, wer_target, debug=False):\n",
    "    \"\"\"Compute array of losses given Lambda, also compute weight schedule\"\"\"\n",
    "    idxs = c_lam(lam, smx)\n",
    "    prediction_wers = []\n",
    "    for idx, threshold_idx in enumerate(idxs):\n",
    "        prediction_wers.append(wers[idx][:threshold_idx+1])\n",
    "        \n",
    "    if debug:\n",
    "        total_length = 0\n",
    "        for prediction_wer in prediction_wers:\n",
    "            total_length += len(prediction_wer)\n",
    "        print(\"Mean set size\", total_length / len(prediction_wers))\n",
    "\n",
    "    return loss(prediction_wers, wer_target)\n",
    "\n",
    "def conformal_risk_control(lam, smx, wers, wer_target, weight_schedule):\n",
    "    n = smx.shape[0]\n",
    "    loss_values = losses(lam, smx, wers, wer_target)\n",
    "    \n",
    "    weighted_sum = 0\n",
    "    for idx, loss in enumerate(loss_values):\n",
    "        weighted_sum += weight_schedule[idx] * loss\n",
    "    \n",
    "    return weighted_sum / sum(weight_schedule) - ((n+1)/n*alpha - 1/(n+1))\n",
    "\n",
    "def compute_lamhat(\n",
    "        confidence_scores, \n",
    "        word_error_rates, \n",
    "        wer_target, \n",
    "        weight_schedule):\n",
    "    \"\"\"Search for value of lambda that controls the WER\"\"\"\n",
    "    crc_partial = functools.partial(\n",
    "        conformal_risk_control, smx=confidence_scores, wers=word_error_rates, \n",
    "        wer_target=wer_target, weight_schedule=weight_schedule)\n",
    "    \n",
    "    try:\n",
    "        return brentq(crc_partial, 0, 1)\n",
    "    except ValueError as e:\n",
    "        if crc_partial(0) > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36804c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Visualise Empirical loss curves\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def crc_util(lam, smx, wers, wer_target, weight_schedule):\n",
    "    \"\"\"Utility function to visualise empirical loss\"\"\"\n",
    "    loss_values = losses(lam, smx, wers, wer_target)\n",
    "    \n",
    "    weighted_sum = 0\n",
    "    for idx, loss in enumerate(loss_values):\n",
    "        weighted_sum += weight_schedule[idx] * loss\n",
    "\n",
    "    return weighted_sum / sum(weight_schedule)\n",
    "\n",
    "\n",
    "\n",
    "x_values = np.arange(0, 1.2, 0.01)\n",
    "\n",
    "# Define the first set of data\n",
    "smx_calib = np.array(calibration_confidence_scores)\n",
    "wers_calib = np.array(calibration_word_error_rates)\n",
    "\n",
    "crc_partial_calib_1 = functools.partial(\n",
    "    crc_util, \n",
    "    smx=smx_calib, \n",
    "    wers=wers_calib, \n",
    "    wer_target=threshold, \n",
    "    weight_schedule=[1] * len(calibration_ids))\n",
    "\n",
    "print(f\"Calibration data: Min coverage = {1-crc_partial_calib_1(0)}, max coverage = {1-crc_partial_calib_1(1)})\")\n",
    "\n",
    "y_values_1 = [crc_partial_calib_1(x) for x in x_values]\n",
    "plt.plot(x_values, y_values_1, label='Calibration Data')\n",
    "\n",
    "\n",
    "crc_partial_calib_2 = functools.partial(\n",
    "    crc_util, smx=smx_calib, wers=wers_calib, \n",
    "    wer_target=threshold, weight_schedule=weights)\n",
    "\n",
    "print(f\"Weighted Calibration Data: min coverage = {1-crc_partial_calib_2(0)}, max coverage = {1-crc_partial_calib_2(1)})\")\n",
    "\n",
    "y_values_calib_2 = [crc_partial_calib_2(x) for x in x_values]\n",
    "plt.plot(x_values, y_values_calib_2, label='Weighted Calibration Data')\n",
    "\n",
    "\n",
    "smx_test= np.array(validation_confidence_scores)\n",
    "wers_test = np.array(validation_word_error_rates)\n",
    "\n",
    "crc_partial_test = functools.partial(\n",
    "    crc_util, \n",
    "    smx=smx_test, \n",
    "    wers=wers_test, \n",
    "    wer_target=threshold, \n",
    "    weight_schedule=[1] * len(validation_ids))\n",
    "\n",
    "print(f\"Validation Data: min coverage = {1-crc_partial_test(0)}, max coverage = {1-crc_partial_test(1)})\")\n",
    "\n",
    "y_values_test = [crc_partial_test(x) for x in x_values]\n",
    "plt.plot(x_values, y_values_test, label='Test Data')\n",
    "\n",
    "\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('Empirical Loss')\n",
    "plt.title('Plot of Empirical Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7726bd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Compute lambda hat\"\"\"\n",
    "\n",
    "lamhat = compute_lamhat(np.array(calibration_confidence_scores), np.array(calibration_word_error_rates), threshold, weights)\n",
    "lamhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950ce42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Compute the coverage and mean set size for calibration set\"\"\"\n",
    "\n",
    "ls = losses(lamhat, np.array(calibration_confidence_scores), np.array(calibration_word_error_rates), threshold, debug=True)\n",
    "print(\"Coverage: \", 1 - ls.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b398135",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Compute the coverage and mean set size for validataion set\"\"\"\n",
    "\n",
    "ls = losses(lamhat, np.array(validation_confidence_scores), np.array(validation_word_error_rates), threshold, debug=True)\n",
    "print(\"Coverage: \", 1 - ls.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp-snips",
   "language": "python",
   "name": "cp-snips"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
