{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "539d69df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from db import execute_query\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import functools\n",
    "from scipy.optimize import brentq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4496bdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 1\n",
    "alpha = 0.4\n",
    "threshold = 0.4\n",
    "\n",
    "def run_trial(use_transductive=False):\n",
    "    query = f\"\"\"\n",
    "    select audio_id, background_modifier_id, audio_info_id\n",
    "    from audio_data \n",
    "    \"\"\"\n",
    "\n",
    "    class Audio:\n",
    "        def __init__(self, row):\n",
    "            self.audio_id = row[0]\n",
    "            self.background_modifier = row[1]\n",
    "            self.info_id = row[2]\n",
    "\n",
    "    data = execute_query(query)\n",
    "\n",
    "    audio_ids = np.array([Audio(d) for d in data])\n",
    "    background_modifier_ids = np.array([d[1] for d in data])\n",
    "    audio_info_ids = np.array([d[2] for d in data])\n",
    "\n",
    "    labels = np.array(list(zip(background_modifier_ids, audio_info_ids)))\n",
    "    audio_train, audio_test, _, _ = train_test_split(audio_ids, labels, test_size=0.2, stratify=labels)\n",
    "\n",
    "    calibration_ids = [audio.audio_id for audio in audio_train]\n",
    "    calibration_features = [audio.background_modifier for audio in audio_train]\n",
    "\n",
    "    validation_ids = [audio.audio_id for audio in audio_test]\n",
    "    validation_features = [audio.background_modifier for audio in audio_test]\n",
    "\n",
    "    def create_mapping(data):\n",
    "        mapping = {}\n",
    "        idx = 0\n",
    "        for item in data:\n",
    "            audio_id = item[0]\n",
    "            if audio_id not in mapping:\n",
    "                mapping[audio_id] = idx\n",
    "                idx += 1\n",
    "        return mapping\n",
    "\n",
    "    n = len(calibration_ids)\n",
    "    calibration_predictions = [[] for _ in range(n)]\n",
    "    calibration_confidence_scores = [[] for _ in range(n)]\n",
    "    calibration_word_error_rates = [[] for _ in range(n)]\n",
    "    calibration_audio_info_ids = [[] for _ in range(n)]\n",
    "    c_background_modifier_ids = [[] for _ in range(n)]\n",
    "\n",
    "    query = f\"\"\"\n",
    "    select Audio_ID, Prediction, Confidence_Score, Word_Error_Rate, Audio_Info_ID, Background_Modifier_ID\n",
    "    from audio_data \n",
    "    natural join audio_predictions\n",
    "    where audio_id in {tuple(calibration_ids)}\n",
    "    \"\"\"\n",
    "    rows = execute_query(query)\n",
    "    mapping = create_mapping(rows)\n",
    "\n",
    "    for row in rows:\n",
    "        idx = mapping[row[0]]\n",
    "        calibration_predictions[idx].append(row[1])\n",
    "        calibration_confidence_scores[idx].append(row[2])\n",
    "        calibration_word_error_rates[idx].append(row[3])\n",
    "        calibration_audio_info_ids[idx].append(row[4])\n",
    "        c_background_modifier_ids[idx].append(row[5])\n",
    "\n",
    "    n = len(validation_ids)\n",
    "    validation_predictions = [[] for _ in range(n)]\n",
    "    validation_confidence_scores = [[] for _ in range(n)]\n",
    "    validation_word_error_rates = [[] for _ in range(n)]\n",
    "    validation_audio_info_ids = [[] for _ in range(n)]\n",
    "    v_background_modifier_ids = [[] for _ in range(n)]\n",
    "\n",
    "    query = f\"\"\"\n",
    "    select Audio_ID, Prediction, Confidence_Score, Word_Error_Rate, Audio_Info_ID, Background_Modifier_ID\n",
    "    from audio_data \n",
    "    natural join audio_predictions\n",
    "    where audio_id in {tuple(validation_ids)}\n",
    "    \"\"\"\n",
    "    rows = execute_query(query)\n",
    "    mapping = create_mapping(rows)\n",
    "\n",
    "    for row in rows:\n",
    "        idx = mapping[row[0]]\n",
    "        validation_predictions[idx].append(row[1])\n",
    "        validation_confidence_scores[idx].append(row[2])\n",
    "        validation_word_error_rates[idx].append(row[3])\n",
    "        validation_audio_info_ids[idx].append(row[4])\n",
    "        v_background_modifier_ids[idx].append(row[5])\n",
    "\n",
    "    def flat(input_list):\n",
    "        flattened_list = []\n",
    "        for sublist in input_list:\n",
    "            if isinstance(sublist, list):\n",
    "                if sublist:  # Check if the sublist is not empty\n",
    "                    flattened_list.append(sublist[0])\n",
    "            else:\n",
    "                flattened_list.append(sublist)\n",
    "        return flattened_list\n",
    "\n",
    "    calibration_features = flat(c_background_modifier_ids)\n",
    "    validation_features = flat(v_background_modifier_ids)\n",
    "\n",
    "    def compute_weight_schedule(calibration_features, validation_features):\n",
    "        X, y = calibration_features + validation_features, [0] * len(calibration_features) + [1] * len(validation_features)\n",
    "        X, y = np.array(X).reshape(-1, 1), np.array(y)\n",
    "\n",
    "        binary_classifier = RandomForestClassifier()\n",
    "        binary_classifier.fit(X, y)\n",
    "\n",
    "        weight_fn = {}\n",
    "        feature_set = set(calibration_features) | set(validation_features)\n",
    "        for feature in feature_set:\n",
    "            probabilities = binary_classifier.predict_proba([[feature]])[0]\n",
    "            weight_fn[feature] = probabilities[1] / (1 - probabilities[1])\n",
    "\n",
    "        weight_schedule = [weight_fn[feature] for feature in calibration_features]\n",
    "        return weight_schedule, weight_fn, binary_classifier\n",
    "\n",
    "    weights, weight_fn, classifier = compute_weight_schedule(calibration_features, validation_features)\n",
    "\n",
    "    def cumsum_2d_list(lst):\n",
    "        result = []\n",
    "        for row in lst:\n",
    "            cum_sum_row = []\n",
    "            cum_sum = 0\n",
    "            for num in row:\n",
    "                cum_sum += num\n",
    "                cum_sum_row.append(cum_sum)\n",
    "            result.append(cum_sum_row)\n",
    "        return result\n",
    "\n",
    "    def find_first_ge_index(cumsum_list, lam):\n",
    "        for row_idx, value in enumerate(cumsum_list):\n",
    "            if value >= lam:\n",
    "                return row_idx\n",
    "        return len(cumsum_list) - 1\n",
    "\n",
    "    def all_greater_or_equal(w, wer_target):\n",
    "        for element in w:\n",
    "            if element < wer_target:\n",
    "                return 0\n",
    "        return 1\n",
    "\n",
    "    def c_lam(lam, smx):\n",
    "        \"\"\"Compute prediction set indexes using lambda\"\"\"\n",
    "    #     prefix_sums = np.cumsum(smx, axis=1)\n",
    "        prefix_sums = cumsum_2d_list(smx)\n",
    "        threshold_indexes = [None for _ in range(len(prefix_sums))]\n",
    "        for idx, row in enumerate(prefix_sums):\n",
    "            threshold_idx = find_first_ge_index(row, lam)\n",
    "            threshold_indexes[idx] = threshold_idx if row[threshold_idx] >= lam else len(row) - 1\n",
    "        return threshold_indexes\n",
    "\n",
    "    def loss(wers, wer_target):\n",
    "        \"\"\"Compute array of losses\"\"\"\n",
    "        return np.array([all_greater_or_equal(w, wer_target) for w in wers])\n",
    "\n",
    "    def losses(lam, smx, wers, wer_target, debug=False):\n",
    "        \"\"\"Compute array of losses given Lambda, also compute weight schedule\"\"\"\n",
    "        idxs = c_lam(lam, smx)\n",
    "        prediction_wers = []\n",
    "        for idx, threshold_idx in enumerate(idxs):\n",
    "            prediction_wers.append(wers[idx][:threshold_idx+1])\n",
    "\n",
    "        if debug:\n",
    "            total_length = 0\n",
    "            for prediction_wer in prediction_wers:\n",
    "                total_length += len(prediction_wer)\n",
    "            print(\"Mean set size\", total_length / len(prediction_wers))\n",
    "\n",
    "        return loss(prediction_wers, wer_target)\n",
    "\n",
    "    def conformal_risk_control(lam, smx, wers, wer_target, weight_schedule, test_feature_weight=None):\n",
    "        \"\"\"This is where conformal risk control happens\"\"\"\n",
    "        n = len(smx)\n",
    "        loss_values = losses(lam, smx, wers, wer_target)\n",
    "\n",
    "        weighted_sum = 0\n",
    "        for idx, loss in enumerate(loss_values):\n",
    "            weighted_sum += weight_schedule[idx] * loss\n",
    "\n",
    "        if test_feature_weight is None:\n",
    "            return weighted_sum / sum(weight_schedule) - ((n+1)/n*alpha - 1/(n+1))\n",
    "\n",
    "        return (weighted_sum + test_feature_weight * B) / (sum(weight_schedule) + test_feature_weight) - ((n+1)/n*alpha - 1/(n+1))\n",
    "\n",
    "    def compute_lamhat(\n",
    "            confidence_scores, \n",
    "            word_error_rates, \n",
    "            wer_target, \n",
    "            weight_schedule,\n",
    "            test_feature_weight=None):\n",
    "        \"\"\"Search for value of lambda that controls the WER\"\"\"\n",
    "        crc_partial = functools.partial(\n",
    "            conformal_risk_control, smx=confidence_scores, wers=word_error_rates, \n",
    "            wer_target=wer_target, weight_schedule=weight_schedule,\n",
    "            test_feature_weight=test_feature_weight)\n",
    "        try:\n",
    "            return brentq(crc_partial, 0, 1)\n",
    "        except ValueError as e:\n",
    "            if crc_partial(0) > 0:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "            \n",
    "    if use_transductive == False:\n",
    "        lamhat = compute_lamhat(calibration_confidence_scores, calibration_word_error_rates, threshold, weights)\n",
    "        ls = losses(lamhat, validation_confidence_scores, validation_word_error_rates, threshold, debug=True)\n",
    "        return 1 - ls.mean()\n",
    "    \n",
    "    \"\"\"Use the transductive approach\"\"\"\n",
    "    n = len(validation_confidence_scores)\n",
    "    lamhats = np.empty(n)\n",
    "    ls = np.empty(n)\n",
    "    set_sizes = np.empty(n)\n",
    "\n",
    "    for idx in range(n):\n",
    "        feature = validation_features[idx]\n",
    "        weight = weight_fn[feature]\n",
    "\n",
    "        vcs = np.array([validation_confidence_scores[idx]])\n",
    "        vwer = np.array([validation_word_error_rates[idx]])\n",
    "\n",
    "        lamhat = compute_lamhat(\n",
    "            np.array(calibration_confidence_scores), \n",
    "            np.array(calibration_word_error_rates), \n",
    "            threshold, \n",
    "            weights,\n",
    "            test_feature_weight=weight\n",
    "        )\n",
    "\n",
    "        lamhats[idx] = lamhat\n",
    "        ls[idx] = losses(lamhat, vcs, vwer, threshold)\n",
    "        set_sizes[idx] = c_lam(lamhat, vcs)[0] + 1\n",
    "        \n",
    "    print(\"Mean set size: \", set_sizes.mean())\n",
    "    return 1 - ls.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0fe4fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean set size 4.155315085932527\n",
      "Mean set size 4.181413112667091\n",
      "Mean set size 4.064926798217695\n",
      "Mean set size 4.085932527052832\n",
      "Mean set size 4.0299172501591345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6011457670273711"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = 5\n",
    "results = [run_trial() for _ in range(R)]\n",
    "C_hat = sum(results)/len(results)\n",
    "C_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c6f164",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 5\n",
    "results = [run_trial(use_transductive=True) for _ in range(R)]\n",
    "C_hat = sum(results)/len(results)\n",
    "C_hat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp-snips",
   "language": "python",
   "name": "cp-snips"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
